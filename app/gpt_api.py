import os
from pathlib import Path
from dotenv import load_dotenv

ENV_PATH = Path(__file__).resolve().parents[1] / ".env"   # -> backend/.env
load_dotenv(ENV_PATH)

from openai import OpenAI

import asyncio
import time
from fastapi import HTTPException, FastAPI, UploadFile, File
from fastapi.responses import JSONResponse
prompt1 = """Analiza el proyecto HTML que te voy a compartir en formato .tar y escribe un breve feedback sobre √©l, indicando los errores y fortalezas. Soy un estudiante que est√° cursando un curso
de programaci√≥n y quiero asegurarme de que mi proyecto est√© correcto y cumpla con la
actividad asignada. La actividad asignada es la siguiente: """
prompt2 = """El feedback debe estar estructurado en una lista anidada con tres encabezados principales: "Errores", "Mejoras sugeridas" y "Fortalezas", cada uno con 1 a 3
√≠tems con una breve descripci√≥n (ejemplo: "Uso de caracteres especiales: Aseg√∫rate de
usar entidades HTML como &ntilde; para la letra √± para garantizar compatibilidad.").
Adem√°s, menciona expl√≠citamente si falt√≥ cumplir alguna instrucci√≥n de la actividad
asignada. Por ejemplo: "Te falt√≥ realizar la pregunta 3 de la actividad." Considera los
contenidos que se me han ense√±ado en el curso para generar el feedback. Utiliza un tono
formal y no incluyas introducciones ni comentarios adicionales, solo proporciona la lista
anidada con el feedback."""
instructions = '''Eres un experimentado profesor de programaci√≥n especializado en revisi√≥n de c√≥digo. 
Tu objetivo es evaluar el c√≥digo entregado por tus alumnos, identificando errores y 
destacando sus fortalezas. Debes interpretar el c√≥digo proporcionado y proporcionar 
feedback detallado y preciso. En tu retroalimentaci√≥n, se√±ala los errores m√°s cr√≠ticos, 
ofrece sugerencias claras y pr√°cticas para mejorar la soluci√≥n, y destaca las partes del 
c√≥digo que est√©n bien implementadas. Usa un tono constructivo y pedag√≥gico para fomentar 
el aprendizaje y el desarrollo de habilidades.
Aparte si te lo piden debes generar preguntas para evaluar a tus alumnos basado en los archivos que contengas. Estas preguntas pueden ser de desarrollo, alternativas, o verdadero y falso dependiendo de lo solicitado. 
'''

'''
UPLOAD_FOLDER = 'uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)'


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in {'pdf'}

async def create_assistant(descripcion, instruccions, model="gpt-4-turbo-preview"):
    try:
        assistant = openai.Assistant.create(
            description=descripcion,
            instructions=instruccions,
            model=model,
            tools=[{"type": "file_search"}]
        )
        return assistant
    except openai.Error as e:
        raise HTTPException(status_code=500, detail=str(e))

async def upload_file_to_assistant(file, assistant_id):
    if not allowed_file(file.filename):
        raise HTTPException(status_code=400, detail="File type not allowed")

    file_location = os.path.join(UPLOAD_FOLDER, file.filename)
    with open(file_location, "wb") as f:
        f.write(file.file.read())

    try:
        response = openai.File.create(file=open(file_location), purpose="fine-tune")
        file_id = response['id']
        
        # Optionally link the file with the assistant
        # Here you would add logic to associate the file_id with the assistant_id if needed
        
        return file_id
    except openai.Error as e:
        raise HTTPException(status_code=500, detail=str(e))
    
'''    
openai_key = os.getenv("OPENAI_API_KEY")
if not openai_key:
    raise RuntimeError("‚ùå OPENAI_API_KEY no est√° definida en backend/.env")

# Configurar el cliente OpenAI con tu clave API para iniciar sesion
client = OpenAI(api_key=openai_key)

#NOGPT
async def crear_prompt(texto):
    # Crear el nuevo prompt con el texto recibido entre prompt1 y prompt2
    nuevo_prompt = f"{prompt1}\n{texto}\n{prompt2}"
    return nuevo_prompt

def crear_assistant():
    '''
    Funci√≥n para crear un asistente con vector store
    Retorna: assistant_id, vector_store_id
    '''
    try:
        # Primero crear el vector store
        vector_store = client.beta.vector_stores.create(
            name=f"VectorStore_{int(time.time())}"
        )
        print(f"üóÇÔ∏è Vector Store creado: {vector_store.id}")

        # Luego crear el assistant con el vector store
        assistant = client.beta.assistants.create(
            instructions=instructions,
            tools=[{"type": "file_search"}],
            tool_resources={
                "file_search": {
                    "vector_store_ids": [vector_store.id]
                }
            },
            model="gpt-4o-mini",
        )
        print(f"üë®‚Äçüíº Assistant creado: {assistant.id}")

        return assistant.id, vector_store.id

    except Exception as e:
        print(f"‚ùå Error creando assistant: {str(e)}")
        raise


async def verificar_estado_vector_store(vector_store_id: str):
    """
    Verifica el estado actual del vector store
    """
    try:
        # Verificar vector store
        vs = client.beta.vector_stores.retrieve(vector_store_id)
        print(f"üîç Vector Store: {vs.id}")
        print(f"   - Estatus: {vs.status}")
        print(f"   - Uso: {vs.usage_bytes} bytes")
        print(f"   - Archivos: {vs.file_counts}")

        # Listar archivos en el vector store
        files = client.beta.vector_stores.files.list(vector_store_id=vector_store_id)
        
        print(f"   - Archivos presentes: {len(files.data)}")
        for file in files.data:
            print(f"     üìÑ {file.id}: {file.status} (Tipo: {file.object})")

        return vs

    except Exception as e:
        print(f"‚ùå Error verificando vector store: {e}")
        return None
async def limpiar_vector_store(vector_store_id: str):
    """Elimina todos los archivos de un vector store y espera a que se complete"""
    try:
        files = client.beta.vector_stores.files.list(vector_store_id=vector_store_id)
        print(f"üóëÔ∏è Eliminando {len(files.data)} archivos...")
        
        # Eliminar todos los archivos
        for file in files.data:
            client.beta.vector_stores.files.delete(
                vector_store_id=vector_store_id,
                file_id=file.id
            )
            print(f"   - Solicitada eliminaci√≥n de: {file.id}")
        
        # ‚úÖ ESPERAR A QUE TODAS LAS ELIMINACIONES SE COMPLETEN
        print("‚è≥ Esperando a que se complete la limpieza...")
        await asyncio.sleep(5)  # Espera inicial
        
        # Verificar peri√≥dicamente hasta que est√© vac√≠o
        max_attempts = 10
        for attempt in range(max_attempts):
            remaining_files = client.beta.vector_stores.files.list(vector_store_id=vector_store_id)
            
            if len(remaining_files.data) == 0:
                print("‚úÖ Vector store completamente limpiado")
                return
                
            print(f"üîÑ Intentando {attempt + 1}/{max_attempts}: {len(remaining_files.data)} archivos pendientes...")
            await asyncio.sleep(3)  # Esperar entre intentos
            
        print("‚ö†Ô∏è  Algunos archivos a√∫n pueden estar en proceso de eliminaci√≥n")
            
    except Exception as e:
        print(f"‚ùå Error limpiando: {e}")





#Funcion para actualizar vector_store recibe id vector store y archifo (file), retorna el ID DEL ARCHIVO
async def actualizar_vector_store(vector_store_id, archivo):
    '''
    Actualiza el vector store con un nuevo archivo usando batches.
    Retorna: file_id, batch_id
    '''
    # Subir archivo a OpenAI
    nuevo_archivo = client.files.create(
        file=archivo,
        purpose='assistants'
    )

    # Crear batch con el archivo subido
    batch_add = client.beta.vector_stores.file_batches.upload_and_poll(
        vector_store_id=vector_store_id,
        files=[nuevo_archivo.id]
    )

    print(f"üì¶ Batch creado: {batch_add.id} para vector {vector_store_id}")
    return nuevo_archivo.id, batch_add.id


async def subir_corpus(assistant_id: str, upload_file: UploadFile, vector_store_id: str):
    '''
    Versi√≥n simple - sube el archivo y retorna sin esperar verificaci√≥n
    '''
    try:
        print(f"üîç Procesando: {upload_file.filename}")
        
        # 1Ô∏è‚É£ Leer y subir archivo a OpenAI
        file_content = await upload_file.read()
        from io import BytesIO
        file_like_object = BytesIO(file_content)
        
        uploaded_file = client.files.create(
            file=(upload_file.filename, file_like_object, upload_file.content_type),
            purpose="assistants"
        )
        
        print(f"üìÑ Archivo subido a OpenAI: {uploaded_file.id}")

        # 2Ô∏è‚É£ Agregar archivo al vector store
        vector_store_file = client.beta.vector_stores.files.create(
            vector_store_id=vector_store_id,
            file_id=uploaded_file.id
        )
        
        print(f"üì¶ Archivo agregado al vector store: {vector_store_file.id}")

        # 3Ô∏è‚É£ ‚úÖ SOLUCI√ìN: Esperar un tiempo fijo sin verificar estado
        print("‚è≥ Esperando procesamiento del archivo...")
        await asyncio.sleep(10)  # Espera fija de 10 segundos

        # Verificaci√≥n r√°pida final (opcional)
        try:
            file_status = client.beta.vector_stores.files.retrieve(
                vector_store_id=vector_store_id,
                file_id=vector_store_file.id
            )
            print(f"üìä Estado final: {file_status.status}")
        except Exception as e:
            print(f"‚ö†Ô∏è  No se pudo verificar estado final: {e}")

        print("‚úÖ Archivo enviado para procesamiento")
        return {
            "file_id": uploaded_file.id, 
            "batch_id": vector_store_file.id
        }

    except Exception as e:
        print(f"‚ùå Error en subir_corpus_simple: {str(e)}")
        raise Exception(f"Error subiendo archivo: {str(e)}")

async def eliminar_archivo(archivo_id):
    """
    Elimina un archivo de la API de GPT de OpenAI utilizando su ID de manera as√≠ncrona.
    
    Args:
        archivo_id (str): El ID del archivo a eliminar.
        
    Returns:
        dict: La respuesta de la API de OpenAI.
    """
    try:
        response = await asyncio.to_thread(client.files.delete, archivo_id)
        print(f"Archivo {archivo_id} eliminado correctamente.")
        return response

    except Exception as e:
        print(f"Error al eliminar el archivo: {e}")

def mostrar_mensajes_assistant(messages):
    ''''
    fUNCION AUXILIAR Para obtener el resultado del prompt como texto plano
    '''

    mensajes_assistant = [message for message in messages if message.role == "assistant"]
    mensajes_texto = []

    for message in mensajes_assistant:
        if isinstance(message.content, list):
            for content in message.content:
                print(f"Content type: {type(content)}")
                # Acceso basado en la estructura esperada del objeto
                if content.type == 'text':
                    print(content.text.value)
                    mensajes_texto.append(content.text.value.replace('\n', '<br>'))

                    if hasattr(content.text, 'annotations'):
                        for annotation in content.text.annotations:
                            print(f"Annotation Text: {annotation.text}")
                            if hasattr(annotation, 'file_path') and hasattr(annotation.file_path, 'file_id'):
                                print(f"File_Id: {annotation.file_path.file_id}")
                                annotation_data = client.files.content(annotation.file_path.file_id)
                                annotation_data_bytes = annotation_data.read()

                                filename = annotation.text.split('/')[-1]

                                with open(f"{filename}", "wb") as file:
                                    file.write(annotation_data_bytes)
                            else:
                                print("La anotaci√≥n no tiene un archivo asociado.")
                elif content.type == 'image_file':
                    print(f"Image File ID: {content.image_file.file_id}")
        else:
            print("El contenido del mensaje no est√° en el formato esperado.")

    return mensajes_texto

#NO GPT
def obtener_prompt(messages):
    for thread_message in messages.data:
        # Iterate over the 'content' attribute of the ThreadMessage, which is a list
        for content_item in thread_message.content:
            # Assuming content_item is a MessageContentText object with a 'text' attribute
            # and that 'text' has a 'value' attribute, print it
            return(content_item.text.value)

async def obtener_feedback(assistant_id, archivo, prompt):
    archivo = client.files.create(file=archivo, purpose='assistants')
    thread = client.beta.threads.create(
        messages=[
            {
                "role": "user",
                "content": prompt,
                "attachments": [
                    {
                        "file_id": archivo.id,
                        "tools": [{"type": "code_interpreter"}]
                    }
                ]
            }
        ]
    )
    run = client.beta.threads.runs.create(
        thread_id=thread.id,
        assistant_id=assistant_id
    )
    
    while run.status not in ["completed", "failed"]:
        run = client.beta.threads.runs.retrieve(
            thread_id=thread.id,
            run_id=run.id
        )
        print(run.status)
        await asyncio.sleep(1)  # Use asyncio.sleep to not block the event loop

    messages = client.beta.threads.messages.list(
        thread_id=thread.id,
    )
    id = archivo.id
    #client.files.delete(archivo.id) ahora se borra al borrar la actividad pero se podria eliminar altok
    return mostrar_mensajes_assistant(messages), id

# Para ejecutar la funci√≥n asincr√≥nica desde un contexto sincr√≥nico
def obtener_feedback_sync(archivo, prompt):
    return asyncio.run(obtener_feedback(archivo, prompt))

#NUKE()


